---
title: "750 Final Project"
output: html_notebook
---
```{r}
library(dplyr)
library(ggplot2)
library(gridExtra)
```



```{r}
MI <- read.csv("12045261/Myocardial infarction complications Database.csv")
MI <- MI[,c(2:112, 121)]
dim(MI) # 1700, 112

# variables with more than 10% missing values are excluded from the analysis
NApercent <- colSums(is.na(MI)) / nrow(MI)
selectcol <- NApercent[NApercent < 0.1]
MI.work <- MI[, names(selectcol)]
dim(MI.work) # 1700 112

# dimension of the dataset used in the analysis
MI.work <- na.omit(MI.work)
dim(MI.work) # 1074 95
```

### descriptive analysis of demographic information
```{r}
mean(MI.work$AGE) # 60.73
median(MI.work$AGE) # 62
age.hist <- ggplot(MI.work, aes(MI.work$AGE)) + geom_histogram() + 
  labs(x = "age", y = "count") + 
  geom_vline(xintercept = mean(MI.work$AGE), color = "blue") + 
  geom_vline(xintercept = median(MI.work$AGE), linetype = "dotted") +
  annotate("text", x = 40, y = 120, label = "mean = 60.73") +
  annotate("text", x = 40, y = 110, label = "median = 62") 

table(MI.work$SEX)
sex.plot <- ggplot(MI.work, aes(as.factor(MI.work$SEX))) + geom_bar() + 
  labs(x = "sex", y = "") + 
  scale_x_discrete(labels = c("female", "male")) +
  annotate("text", x = 1, y = 780, label = "female = 380") +
  annotate("text", x = 1, y = 720, label = "male = 649") 

table(MI.work$ZSN)
chf.plot <- ggplot(MI.work, aes(as.factor(MI.work$ZSN))) + geom_bar() + 
  labs(x = "CHF", y = "") + 
  scale_x_discrete(labels = c("no", "yes")) +
  annotate("text", x = 2, y = 780, label = "no = 806") +
  annotate("text", x = 2, y = 720, label = "yes = 268") 

grid.arrange(age.hist, sex.plot, chf.plot, nrow = 1)
```



### Regular GLM with subset seelction (Alona)

```{r}
# choice model: subset of predictors at the time of admission
mi.sub <- select(MI.work, -c(R_AB_1_n, R_AB_2_n, R_AB_3_n, NA_R_1_n, NA_R_2_n, NA_R_3_n, NOT_NA_1_n, NOT_NA_2_n, NOT_NA_3_n))
dim(mi.sub)

#choice model: 743
choice <- MI.work %>% 
  select(ZSN, AGE, SEX, IBS_POST, endocr_01, endocr_02, K_SH_POST, ritm_ecg_p_01, 
         TIME_B_S, L_BLOOD)
dim(choice)
```


```{r}
#Backward selection - on the entire set.
glm.fit <-  glm(ZSN ~., data = MI.work, family = "binomial") 
#glm.fit <-  glm(ZSN ~., data = mi.sub, family = "binomial") 
best.fit.b <- stepAIC(glm.fit, scope=list(lower = ~ 1, upper = formula(glm.fit)), 
                      trace =F, direction = "backward")
best.fit.f <- stepAIC(glm.fit, scope=list(lower = ~ 1, upper = formula(glm.fit)),
                      trace =F, direction = "forward")
#length(best.fit.b$coefficients)
```


```{r}
# full model
glm.fit <-  glm(ZSN ~., data = MI.work, family = binomial) 
pred <- predict(glm.fit, type="response")
summary(glm.fit)

# null model
glm.fit.0 <-  glm(ZSN ~1., data = MI.work, family = binomial) 
summary(glm.fit.0)

```

```{r warning=FALSE}
k=nrow(choice)
pred.train=rep(0,k)
error.test=rep(0,k)
pred=rep(0,k)
train.error=rep(0,k)
pred.test=rep(0,k)
probs.test=rep(0,k)
set.seed(1)

# LOOCV for subset choice model.
for(j in 1:k){
  glm.fit <-  glm(ZSN ~., data =choice[-j,], family = binomial) 
  probt <- predict(glm.fit, type="response")
  predt <- rep(0,k)
  predt[probt>0.5]=1
  pred.train[j] <- mean(predt == choice[-j,]$ZSN) 
  probs.test[j] <- predict(glm.fit, newdata = choice[j,], type="response")
  pred.test[j] <- (probs.test[j]>.5)
  error.test[j] <- (pred.test[j]!=choice[j,]$ZSN)
}
mean(error.test)
```


```{r warning=FALSE}
k=nrow(mi.sub)
pred.train=rep(0,k)
error.test=rep(0,k)
pred=rep(0,k)
train.error=rep(0,k)
pred.test=rep(0,k)
probs.test=rep(0,k)
set.seed(1)

# LOOCV for subset of predictors at time of admission.
for(j in 1:k){
  glm.fit <-  glm(ZSN ~., data = mi.sub[-j,], family = binomial) 
  probt <- predict(glm.fit, type="response")
  predt <- rep(0,k)
  predt[probt>0.5]=1
  pred.train[j] <- mean(predt == mi.sub[-j,]$ZSN) 
  probs.test[j] <- predict(glm.fit, newdata = mi.sub[j,], type="response")
  pred.test[j] <- (probs.test[j]>.5)
  error.test[j] <- (pred.test[j]!=mi.sub[j,]$ZSN)
}
mean(error.test)
```


```{r ,warning=FALSE}
k=nrow(MI.work)
pred.train=rep(0,k)
error.test=rep(0,k)
pred=rep(0,k)
train.error=rep(0,k)
pred.test=rep(0,k)
probs.test=rep(0,k)
set.seed(1)

# LOOCV for full model
for(j in 1:k){
  glm.fit <-  glm(ZSN ~., data = MI.work[-j,], family = binomial) 
  probt <- predict(glm.fit, type="response")
  predt <- rep(0,k)
  predt[probt>0.5]=1
  pred.train[j] <- mean(predt == MI.work[-j,]$ZSN) 
  probs.test[j] <- predict(glm.fit, newdata = MI.work[j,], type="response")
  pred.test[j] <- (probs.test[j]>.5)
  error.test[j] <- (pred.test[j]!=MI.work[j,]$ZSN)
}
mean(error.test)
```

### Penalized GLM
Lasso regression
```{r}
library(glmnet)
# select best lambda via LOOCV 
set.seed(1)
x <- model.matrix(ZSN ~., MI.work)[, -95]
y <- MI.work$ZSN
cv.out.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial", nfolds = nrow(MI.work))
plot(cv.out.lasso)
lambda.best.lasso <- cv.out.lasso$lambda.min

# fit lasso regression on the dataset
mod.lasso <- glmnet(x, y, alpha = 1, lambda = lambda.best.lasso, family = "binomial")
mod.lasso$beta

# compute LOOCV test error rate of Lasso regression
lasso.pred.error <- rep(0, n = 1:nrow(MI.work))
for (i in 1:nrow(MI.work)){
  x.train <- x[-i, ]
  y.train <- y[-i]
  x.test <- as.matrix(x[i, ])
  y.test <- y[i]
  
  mod <- glmnet(x.train, y.train, alpha = 1, lambda = lambda.best.lasso, family = "binomial")
  sum(diag(table(predict(mod, newx = x.train, s =lambda.best.lasso, type = "class"), y.train))) / nrow(x.train)

  lasso.pred <- predict(mod, newx = t(data.matrix(x.test)), s = lambda.best.lasso, type = "class")
  lasso.pred.error[i] <- ifelse( lasso.pred != y.test, 1, 0)
}
mean(lasso.pred.error) # 0.255
# 17 parameters selected by lasso
```

Ridge regression
```{r}
set.seed(1)
cv.out.ridge <- cv.glmnet(x, y, alpha = 0, family = "binomial", nfolds = nrow(MI.work))
plot(cv.out.ridge)
lambda.best.ridge <- cv.out.ridge$lambda.min

# fit ridge regression on the dataset
mod.ridge <- glmnet(x, y, alpha = 0, lambda = lambda.best.ridge, family = "binomial")
mod.ridge$beta

# compute LOOCV test error rate of ridge regression
ridge.pred.correct <- rep(0, n = 1:nrow(MI.work))
for (i in 1:nrow(MI.work)){
  x.train <- x[-i, ]
  y.train <- y[-i]
  x.test <- as.matrix(x[i, ])
  y.test <- y[i]
  
  mod <- glmnet(x.train, y.train, alpha = 0, lambda = lambda.best.lasso, family = "binomial")
  sum(diag(table(predict(mod, newx = x.train, s =lambda.best.lasso, type = "class"), y.train))) / nrow(x.train)

  ridge.pred <- predict(mod, newx = t(data.matrix(x.test)), s = lambda.best.lasso, type = "class")
  ridge.pred.correct[i] <- ifelse(ridge.pred == y.test, 1, 0)
}
mean(ridge.pred.correct)
```


# KNN
```{r}
library(class)
# use LOOCV to determine the best number of K
x.matrix <- as.matrix(MI.work[, -95])
k <- c(1:100)
pred <- rep(0, nrow(MI.work))
pred.error <- rep(0, length(k))


for (j in 1:length(k)){
        for (i in 1:nrow(MI.work)){
                # set up training set and testing set
                train.x <- x.matrix[-i, ]
                test.x <- x.matrix[i, ]
                train.ZSN <- MI.work$ZSN[-i]
                test.ZSN <- MI.work$ZSN[i]
                
                set.seed(1)
                knn.pred <-  knn(train.x, test.x, train.ZSN, k = k[j])
                pred[i] <- ifelse(knn.pred != test.ZSN, 1, 0)
        }
        
        pred.error[j] <- mean(pred)
}

which.min(pred.error) #54
knn.output <- as.data.frame(cbind(pred.error, k))
ggplot(knn.output, aes(y = pred.error, x = k)) + geom_point() + labs(title = "KNN test error rate by number of k", x = "k", y = "LOOCV test error rate") + geom_vline(xintercept = which.min(pred.error), color = "blue", linetype = "dotted") + geom_vline(xintercept = 41, color = "red", linetype = "dotted") + scale_x_continuous(breaks = c(0, 25, 41, 50, 54, 75, 100)) 
```

```{r}
# compute prediction error rate
pred41 <- knn(MI.work[, -95], MI.work[, -95], MI.work$ZSN, k = 32)
mean(pred41 != MI.work$ZSN)

pred54 <- knn(MI.work[, -95], MI.work[, -95], MI.work$ZSN, k = 45)
mean(pred54 != MI.work$ZSN)
```







