---
title: "750 Final Project"
output:
<<<<<<< HEAD
  html_notebook: default
  pdf_document: default
=======
  html_document:
    df_print: paged
>>>>>>> a0a01a189b5440a37d70679af48ed162537f42ae
---
```{r}
library(dplyr)
library(ggplot2)
library(gridExtra)
library(kableExtra)
library(stepPlr)
library(knitr)
```



```{r}
MI <- read.csv("12045261/Myocardial infarction complications Database.csv")
MI <- MI[,c(2:112, 121)]
dim(MI) # 1700, 112

# variables with more than 10% missing values are excluded from the analysis
NApercent <- colSums(is.na(MI)) / nrow(MI)
selectcol <- NApercent[NApercent < 0.1]
MI.work <- MI[, names(selectcol)]
dim(MI.work) # 1700 112

# dimension of the dataset used in the analysis
MI.work <- na.omit(MI.work)
dim(MI.work) # 1074 95
```

### descriptive analysis of demographic information
```{r}
mean(MI.work$AGE) # 60.73
median(MI.work$AGE) # 62
age.hist <- ggplot(MI.work, aes(MI.work$AGE)) + geom_histogram() + 
  labs(x = "age", y = "count") + 
  geom_vline(xintercept = mean(MI.work$AGE), color = "blue") + 
  geom_vline(xintercept = median(MI.work$AGE), linetype = "dotted") +
  annotate("text", x = 40, y = 120, label = "mean = 60.73") +
  annotate("text", x = 40, y = 110, label = "median = 62") 

table(MI.work$SEX)
sex.plot <- ggplot(MI.work, aes(as.factor(MI.work$SEX))) + geom_bar() + 
  labs(x = "sex", y = "") + 
  scale_x_discrete(labels = c("female", "male")) +
  annotate("text", x = 1, y = 780, label = "female = 380") +
  annotate("text", x = 1, y = 720, label = "male = 649") 

table(MI.work$ZSN)
chf.plot <- ggplot(MI.work, aes(as.factor(MI.work$ZSN))) + geom_bar() + 
  labs(x = "CHF", y = "") + 
  scale_x_discrete(labels = c("no", "yes")) +
  annotate("text", x = 2, y = 780, label = "no = 806") +
  annotate("text", x = 2, y = 720, label = "yes = 268") 

grid.arrange(age.hist, sex.plot, chf.plot, nrow = 1)
```



### Regular GLM with subset seelction (Alona)

```{r}
# choice model: subset of predictors at the time of admission
mi.sub <- select(MI.work, -c(R_AB_1_n, R_AB_2_n, R_AB_3_n, NA_R_1_n, NA_R_2_n, NA_R_3_n, NOT_NA_1_n, NOT_NA_2_n, NOT_NA_3_n))
dim(mi.sub)

#choice model: 743
choice <- MI.work %>% 
  select(ZSN, AGE, SEX, IBS_POST, endocr_01, endocr_02, K_SH_POST, ritm_ecg_p_01, 
         TIME_B_S, L_BLOOD)
dim(choice)
```


```{r warning=FALSE}
#Backward selection - on the entire set.
glm.fit <-  glm(ZSN ~., data = MI.work, family = "binomial") 
#glm.fit <-  glm(ZSN ~., data = mi.sub, family = "binomial") 
best.fit.b <- step(glm.fit, scope=list(lower = ~ 1, upper = formula(glm.fit)), 
                      trace =F, direction = "backward")
best.fit.f <- step(glm.fit, scope=list(lower = ~ 1, upper = formula(glm.fit)),
                      trace =F, direction = "forward")
summary(best.fit.b)$aic
length(best.fit.b$coefficients)

# AIC - 1087

p.value=1-pchisq(deviance(best.fit.b),best.fit.b$df.residual)

backwardset <- MI.work %>% 
  select(ZSN,AGE,STENOK_AN,FK_STENOK,ZSN_A,np_08,np_09,
         endocr_01,zab_leg_01,FIB_G_POST,ant_im,lat_im,
         inf_im,ritm_ecg_p_02,ritm_ecg_p_04,n_r_ecg_p_02,
         n_p_ecg_p_04,n_p_ecg_p_06,fibr_ter_03,fibr_ter_06,
         TIME_B_S,NA_R_2_n,NOT_NA_1_n,GEPAR_S_n,
         TIKL_S_n)

kable(summary(best.fit.b)$coef)
kable(summary(glm.fitcr)$coef)
kable(summary(best.fit.b)$coef)
```







```{r}
# full model
glm.fitf <-  glm(ZSN ~., data = MI.work, family = binomial) 
predf <- predict(glm.fitf, type="response")
summary(glm.fitf)$aic
p.value=1-pchisq(deviance(glm.fitf),glm.fitf$df.residual)

# choice model - clinically driven - up to admission vars
glm.fitcc <-  glm(ZSN ~., data =mi.sub, family = binomial) 
predcc <- predict(glm.fitcc, type="response")
summary(glm.fitcc)$aic
p.value=1-pchisq(deviance(glm.fitcc),glm.fitcc$df.residual)

# choice model - 743 plus additional
glm.fitcr <-  glm(ZSN ~., data =choice, family = binomial) 
predcr <- predict(glm.fitcr, type="response")
summary(glm.fitcr)$aic
p.value=1-pchisq(deviance(glm.fitcr),glm.fitcr$df.residual)

# null model
glm.fit.0 <-  glm(ZSN ~1., data = MI.work, family = binomial) 
summary(glm.fit.0)

models.table <- data.frame(type=c("Full","Clinical set choice","Our choice","Backward Selected"),
                           AIC=c(1184.9,1184.086,1167.96,1087.05), 
                           p=c(95,86,10,24),
                           pval=c(0.306,0.247,0.037,0.597))
kable(models.table, caption="Logistic regression models tested")
```

```{r warning=FALSE}
k=nrow(choice)
pred.train=rep(0,k)
error.test=rep(0,k)
pred=rep(0,k)
train.error=rep(0,k)
pred.test=rep(0,k)
probs.test=rep(0,k)
set.seed(1)

# LOOCV for subset choice model.
for(j in 1:k){
  glm.fit <-  glm(ZSN ~., data =choice[-j,], family = binomial) 
  probt <- predict(glm.fit, type="response")
  predt <- rep(0,k)
  predt[probt>0.5]=1
  pred.train[j] <- mean(predt == choice[-j,]$ZSN) 
  probs.test[j] <- predict(glm.fit, newdata = choice[j,], type="response")
  pred.test[j] <- (probs.test[j]>.5)
  error.test[j] <- (pred.test[j]!=choice[j,]$ZSN)
}
mean(error.test)
```


```{r warning=FALSE}
k=nrow(mi.sub)
pred.train=rep(0,k)
error.test=rep(0,k)
pred=rep(0,k)
train.error=rep(0,k)
pred.test=rep(0,k)
probs.test=rep(0,k)
set.seed(1)

# LOOCV for subset of predictors at time of admission.
for(j in 1:k){
  glm.fit <-  glm(ZSN ~., data = mi.sub[-j,], family = binomial) 
  probt <- predict(glm.fit, type="response")
  predt <- rep(0,k)
  predt[probt>0.5]=1
  pred.train[j] <- mean(predt == mi.sub[-j,]$ZSN) 
  probs.test[j] <- predict(glm.fit, newdata = mi.sub[j,], type="response")
  pred.test[j] <- (probs.test[j]>.5)
  error.test[j] <- (pred.test[j]!=mi.sub[j,]$ZSN)
}
mean(error.test)
```


```{r ,warning=FALSE}
k=nrow(MI.work)
pred.train=rep(0,k)
error.test=rep(0,k)
pred=rep(0,k)
train.error=rep(0,k)
pred.test=rep(0,k)
probs.test=rep(0,k)
set.seed(1)

# LOOCV for full model
for(j in 1:k){
  glm.fit <-  glm(ZSN ~., data = MI.work[-j,], family = binomial) 
  probt <- predict(glm.fit, type="response")
  predt <- rep(0,k)
  predt[probt>0.5]=1
  pred.train[j] <- mean(predt == MI.work[-j,]$ZSN) 
  probs.test[j] <- predict(glm.fit, newdata = MI.work[j,], type="response")
  pred.test[j] <- (probs.test[j]>.5)
  error.test[j] <- (pred.test[j]!=MI.work[j,]$ZSN)
}
mean(error.test)
```


```{r ,warning=FALSE}
k=nrow(MI.work)
pred.train=rep(0,k)
error.test=rep(0,k)
pred=rep(0,k)
train.error=rep(0,k)
pred.test=rep(0,k)
probs.test=rep(0,k)
set.seed(1)

# LOOCV for backward selected set model
for(j in 1:k){
  glm.fit <-  glm(ZSN ~., data = backwardset[-j,], family = binomial) 
  probt <- predict(glm.fit, type="response")
  predt <- rep(0,k)
  predt[probt>0.5]=1
  pred.train[j] <- mean(predt == backwardset[-j,]$ZSN) 
  probs.test[j] <- predict(glm.fit, newdata = backwardset[j,], type="response")
  pred.test[j] <- (probs.test[j]>.5)
  error.test[j] <- (pred.test[j]!=backwardset[j,]$ZSN)
}
mean(error.test)
```

```{r}
#prepare data for test error plot 
testerror <- data.frame(n=c(10,17,25,86,89,95),
                        testerr=c(0.249,0.255,0.247,0.262,0.271,0.269),
                        train.err=c(0,0,0,0,0,0),
                        mtype=c("our Choice","LASSO","Backward Selection",
                                "clinical set choice","Ridge","Full"))
library(ggplot2)
 
ggplot(testerror, aes(x=n, y=testerr)) +
  geom_point(size=3) + 
  labs(x="Number of predictors",
       y="Test (prediction) error rate")

```


### Penalized GLM
Lasso regression
```{r}
library(glmnet)
# select best lambda via LOOCV 
set.seed(1)
x <- model.matrix(ZSN ~., MI.work)[, -95]
y <- MI.work$ZSN
cv.out.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial", nfolds = nrow(MI.work))
plot(cv.out.lasso)
lambda.best.lasso <- cv.out.lasso$lambda.min

# fit lasso regression on the dataset
mod.lasso <- glmnet(x, y, alpha = 1, lambda = lambda.best.lasso, family = "binomial")
mod.lasso$beta

# compute LOOCV prediction error rate and test error rate of Lasso regression
lasso.test.error <- rep(0, n = 1:nrow(MI.work))
lasso.pred.error <- rep(0, n = 1:nrow(MI.work))
for (i in 1:nrow(MI.work)){
  x.train <- x[-i, ]
  y.train <- y[-i]
  x.test <- as.matrix(x[i, ])
  y.test <- y[i]
  
  mod <- glmnet(x.train, y.train, alpha = 1, lambda = lambda.best.lasso, family = "binomial")
  
  lasso.pred.error[i] <- mean(predict(mod, newx = x.train, s = lambda.best.lasso, type = "class") != y.train)

  lasso.test.pred[i] <- predict(mod, newx = t(data.matrix(x.test)), s = lambda.best.lasso, type = "class")
  lasso.test.error[i] <- ifelse( lasso.test.pred[i] != y.test, 1, 0)
}
mean(lasso.pred.error) # 0.249
mean(lasso.test.error) # 0.255
# 17 parameters selected by lasso
```


```{r}
# compute test error rate of Lasso regression
x.test <- model.matrix(ZSN ~., MI.work)[, -95]
y.test <- MI.work$ZSN
mean(predict(mod.lasso, newx = x.test, s = lambda.best.lasso, type = "class") != y.test) # 0.2495
```


Ridge regression
```{r}
set.seed(1)
cv.out.ridge <- cv.glmnet(x, y, alpha = 0, family = "binomial", nfolds = nrow(MI.work))
plot(cv.out.ridge)
lambda.best.ridge <- cv.out.ridge$lambda.min

# fit ridge regression on the dataset
mod.ridge <- glmnet(x, y, alpha = 0, lambda = lambda.best.ridge, family = "binomial")
mod.ridge$beta

# compute LOOCV test error rate of ridge regression
ridge.pred.error <- rep(0, n = 1:nrow(MI.work))
ridge.test.error <- rep(0, n = 1:nrow(MI.work))
for (i in 1:nrow(MI.work)){
  x.train <- x[-i, ]
  y.train <- y[-i]
  x.test <- as.matrix(x[i, ])
  y.test <- y[i]
  
  mod <- glmnet(x.train, y.train, alpha = 0, lambda = lambda.best.ridge, family = "binomial")
  
  ridge.pred.error[i] <- mean(predict(mod, newx = x.train, s = lambda.best.ridge, type = "class") != y.train)

  ridge.test.pred <- predict(mod, newx = t(data.matrix(x.test)), s = lambda.best.ridge, type = "class")
  ridge.test.error[i] <- ifelse(ridge.test.pred != y.test, 1, 0)
}
mean(ridge.pred.error) # 0.248
mean(ridge.test.error) # 0.253
```

```{r}
# compare lasso and ridge test error and training error
pglm.table0 <- data.frame(Type = c("Lasso", "Ridge"), Testing_error = c("0.255", "0.253"), Training_error = c("0.249", "0.248"))
pglm.table <- data.frame(t(pglm.table0[, 2:3]))
colnames(pglm.table) <- pglm.table0[, 1]

```

```{r}
kable(pglm.table) %>% kable_styling(font_size = 14, full_width = FALSE) %>% save_kable("error_comparison.pdf")
```


```{r}
tab.lasso <- tidy(coef(mod.lasso))[, -2]
tab.ridge <- tidy(coef(mod.ridge))[, -2]

seperate <- left_join(tab.ridge, tab.lasso, by = "row")
colnames(seperate) <- c("Coefficients", "Lasso estimates", "Ridge estimates")
seperate

share <- left_join(tab.lasso, tab.ridge, by = "row")
colnames(share) <- c("Coefficients", "Lasso estimates", "Ridge estimates")
share
```

```{r}
opts_chunk$set(echo = TRUE)
kable(seperate, caption = "Lasso and Ridge coefficient estimates") %>% kable_styling(font_size = 10, full_width = F) %>% save_kable("seperate.pdf")
```

```{r}
kable(share, caption = "Lasso and Ridge coefficient estimates") %>% kable_styling(font_size = 10, full_width = F) %>% save_kable("share.pdf")
```


# KNN
```{r}
library(class)
# use LOOCV to determine the best number of K
x.matrix <- as.matrix(MI.work[, -95])
k <- c(1:100)
pred <- rep(0, nrow(MI.work))
pred.error <- rep(0, length(k))


for (j in 1:length(k)){
        for (i in 1:nrow(MI.work)){
                # set up training set and testing set
                train.x <- x.matrix[-i, ]
                test.x <- x.matrix[i, ]
                train.ZSN <- MI.work$ZSN[-i]
                test.ZSN <- MI.work$ZSN[i]
                
                set.seed(1)
                knn.pred <-  knn(train.x, test.x, train.ZSN, k = k[j])
                pred[i] <- ifelse(knn.pred != test.ZSN, 1, 0)
        }
        
        pred.error[j] <- mean(pred)
}

which.min(pred.error) #54
knn.output <- as.data.frame(cbind(pred.error, k))
ggplot(knn.output, aes(y = pred.error, x = k)) + geom_point() + labs(title = "KNN test error rate by number of k", x = "k", y = "LOOCV test error rate") + geom_vline(xintercept = which.min(pred.error), color = "blue", linetype = "dotted") + geom_vline(xintercept = 41, color = "red", linetype = "dotted") + scale_x_continuous(breaks = c(0, 25, 41, 50, 54, 75, 100)) 
```

```{r}
# compute prediction error rate
pred41 <- knn(MI.work[, -95], MI.work[, -95], MI.work$ZSN, k = 32)
mean(pred41 != MI.work$ZSN)

pred54 <- knn(MI.work[, -95], MI.work[, -95], MI.work$ZSN, k = 45)
mean(pred54 != MI.work$ZSN)
```







